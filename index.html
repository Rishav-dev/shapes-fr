<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>

<body>
    <button type="button" onclick="init()">Start</button>
    <canvas id="canvas"></canvas>
    <div id="webcam-container"></div>
    <div id="label-container"></div>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script>
    <script type="text/javascript">
        var canvas;
        var context;
        let isDrawing;


        window.onload = function () {
            canvas = document.getElementById('canvas');
            context = canvas.getContext('2d');
            canvas.width = 128;
            canvas.height = 128;
            context.strokeStyle = "#913d88";
            context.lineWidth = 2;

            canvas.onmousedown = startDrawing;
            canvas.onmouseup = stopDrawing;
            canvas.onmousemove = draw;

            function startDrawing(e) {
                isDrawing = true;
                context.beginPath();
                context.moveTo(e.pageX - canvas.offsetLeft, e.pageY - canvas.offsetTop);
            }

            function draw(e) {
                if (isDrawing == true) {
                    var x = e.pageX - canvas.offsetLeft;
                    var y = e.pageY - canvas.offsetTop;

                    context.lineTo(x, y);
                    context.stroke();
                }
            }

            function stopDrawing() {
                isDrawing = false;
            }
        }
        // More API functions here:
        // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image

        // the link to your model provided by Teachable Machine export panel
        const URL = "https://teachablemachine.withgoogle.com/models/O76CzEi4N/";

        let model, canvasElement, labelContainer, maxPredictions;
        canvasElement = document.getElementById("canvas");
        // Load the image model and setup the webcam
        async function init() {
            const modelURL = URL + "model.json";
            const metadataURL = URL + "metadata.json";

            // load the model and metadata
            // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
            // or files from your local hard drive
            // Note: the pose library adds "tmImage" object to your window (window.tmImage)
            model = await tmImage.load(modelURL, metadataURL);
            maxPredictions = model.getTotalClasses();

            // append elements to the DOM

            labelContainer = document.getElementById("label-container");
            for (let i = 0; i < maxPredictions; i++) { // and class labels
                labelContainer.appendChild(document.createElement("div"));
            }
            await predict();
        }


        // run the webcam image through the image model
        async function predict() {
            // predict can take in an image, video or canvas html element
            const prediction = await model.predict(canvasElement);
            console.log(prediction);
            for (let i = 0; i < maxPredictions; i++) {
                const classPrediction =
                    prediction[i].className + ": " + prediction[i].probability.toFixed(2);
                labelContainer.childNodes[i].innerHTML = classPrediction;
            }
        }
    </script>
    <style>
        #canvas {
            position: relative;
            left: calc(50% - 390px);
            top: 50px;
            border: 1px dotted black;
            cursor: crosshair;
            background: white;
        }
    </style>
    </head>

</body>

</html>